# RSS Feed Crawler

Это приложение является учебным пособием по теме "Паттерны конкурентного программирования в Go" на курсе "Продвинутый Go" разработчика в Yandex-практикуме. Цель упражнения — показать развитие приложения от использования таких примитивов синхронизации, как мьютексы и семафоры, к поддержке более продвинутых паттернов, доступных в языке Go.

## Итерация 1 - Базовый каркас приложения

Создаем базовый каркас приложения, которое будет обходить список RSS-лент и формировать общую рассылку для пользователя.

## Итерация 2 - Добавление конкурентного вывода списка лент в консоль

*Конкурентность — это композиция независимо выполняющихся вычислений.*

*Конкурентность — это способ структурирования программного обеспечения, в частности, как способ написания чистого кода, который хорошо взаимодействует с реальным миром.*

*Это не параллелизм.*

*— Роб Пайк*

После добавления конкурентного вывода запускаем приложение и видим, что оно не выводит список подписок, а просто завершается. В чем может быть проблема и как ее решить?

## Итерация 3 - Добавление ожидания завершения горутин

Используем функционал `sync.WaitGroup` для организации ожидания завершения горутин. Запускаем приложение и видим, что оно выводит список подписок. Также можно наблюдать, что подписки могут выводиться в разном порядке. Почему так происходит?

## Итерация 4 - Поддержка `resty` и `feedparser` для получения и парсинга RSS-лент

Добавляем поддержку HTTP клиента `resty` для получения RSS-лент. После запуска приложения видим, что оно "зависает" на ожидании получения данных. Добавляем таймаут в HTTP клиент. Также добавляем поддержку `feedparser` для парсинга лент.

## Итерация 5 - Поддержка эндпоинта `/rss` для получения финальной ленты пользователя

Добавляем эндпоинт `/rss`, который будет возвращать финальную ленту пользователя.

## Итерация 6 - Добавление тикера для периодического опроса RSS-лент

Добавляем `time.Ticker` для периодического опроса RSS-лент. Тикер возвращает канал, который мы используем с конструкцией `select` для получения сообщений от тикера. Как работает `select` и как избежать полной блокировки?

## Итерация 7 - Конкурентный запуск HTTP сервера и краулера для параллельной работы

Убираем запуск бесконечного цикла из краулера, но теперь необходимо ожидать его завершения, чтобы поток выполнения дошел до запуска сервера. Добавляем асинхронный запуск краулера и сервера, а также добавляем блокировку в конце, чтобы приложение не завершалось.

## Итерация 8 - Хранение полученных лент в памяти и шаблон для рендеринга результирующей ленты

На этом этапе мы добавляем слой хранения полученных данных в памяти, который будет обновляться при получении данных из лент. Также добавляем шаблон для рендеринга HTML страницы с RSS лентой пользователя. Какие проблемы могут возникнуть с хранилищем при конкурентном доступе к нему на чтение и запись? Как их можно решить?

## Итерация 9 - Добавление `Mutex` для синхронизации доступа к хранилищу

Если соотношение запросов на запись и чтение сильно смещено в сторону чтения, как мы можем улучшить нашу реализацию? Добавляем поддержку `RWMutex`.

## Итерация 10 - Реализация пула воркеров

В этой итерации мы улучшаем производительность нашего RSS-краулера, реализовав пул воркеров. Это позволяет параллельно обрабатывать несколько RSS-фидов, значительно ускоряя процесс сбора данных.

Основные изменения:

- Использование горутин для создания пула воркеров
- Реализация паттерна fan-in и fan-out
- Реализация паттерна producer-consumer с использованием каналов

## Итерация 11 - Реализация паттерна Consumer Pool

Улучшаем реализацию параллельной обработки данных лент, а также добавляем поддержку буферезированных каналов. В чем отличие буферезированных каналов от небезбуферных? Когда стоит их использовать и для чего?

## Итерация 12 - Graceful Shutdown

В этой итерации добавлен механизм graceful shutdown, который позволяет приложению корректно завершать работу при получении сигнала прерывания. Это обеспечивает:

- Корректное завершение всех текущих операций
- Закрытие открытых соединений
- Освобождение ресурсов перед выходом из программы

Используем `errgroup` для обработки ошибок.

## Использование

1. Запустите приложение:

2. Приложение начнет сбор данных с RSS-фидов и будет доступно по адресу `http://localhost:8080`.

3. Для graceful shutdown отправьте сигнал прерывания (Ctrl+C).

## Структура проекта

- `cmd/crawler/`: Содержит точку входа в приложение
- `internal/crawler/`: Реализация краулера
- `internal/feed/`: Структуры данных и логика для работы с RSS-фидами
- `internal/http/handler/`: HTTP-обработчики

## Дальнейшие улучшения

- Добавление тестов
- Реализация кэширования для уменьшения нагрузки на источники RSS
- Добавление конфигурации через файл или переменные окружения
- Улучшение обработки ошибок и логирования
